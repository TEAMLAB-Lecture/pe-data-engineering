{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "https://github.com/minhnq97/pytorch-transformer-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "VOCAL_FILE = \"vocab.txt\"\n",
    "EMBEDDING_FILE = \"embeddings.npy\"\n",
    "vocal_file_path = os.path.join(DATA_PATH, VOCAL_FILE)\n",
    "embedding_file_path = os.path.join(DATA_PATH, EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [os.path.join(DATA_PATH, filename) \n",
    "             for filename in sorted(os.listdir(DATA_PATH))\n",
    "            if filename[0].isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50,  325,  152,  198,    0,  199,  557, 1797, 2122,   19,  267,\n",
       "       1189, 1196,  789,  466, 1320,  207,   28, 2122,    3,  437,  335,\n",
       "        263,   50,  325,  152,  198,    0,   37,  267,   15,  902,  113,\n",
       "        789,  466,   64,  488,    4,   66,  158,  267,  105,  528, 1797,\n",
       "       2122,    1,  152,  198,    5,  410])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(data_list[0])[:50].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(vocal_file_path, \"r\")\n",
    "vocab = [line.strip().split() for line in f.readlines()]\n",
    "vocab_list = [[line[0], int(line[1])] for line in vocab]\n",
    "vocab = {key: value for value, key  in vocab_list}\n",
    "vocab_array = np.array([word for word, _ in vocab_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sau cứu tự trở của máy phí tiger e cũng nội rau biết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/0.npy',\n",
       " 'data/1.npy',\n",
       " 'data/2.npy',\n",
       " 'data/3.npy',\n",
       " 'data/4.npy',\n",
       " 'data/5.npy',\n",
       " 'data/6.npy',\n",
       " 'data/7.npy',\n",
       " 'data/8.npy',\n",
       " 'data/9.npy']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sau cứu tự trở của máy phí tiger e cũng nội rau biết. cải tương nghèo ý ra e là tích tiếng lúc sau cứu tự trở của nhưng nội khi cà mình cải tương đồng tinh một cơ tài nội chủ hoàng tiger e và tự trở các viện'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab_array[np.load(data_list[0])[:50].astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/0.npy',\n",
       " 'data/1.npy',\n",
       " 'data/2.npy',\n",
       " 'data/3.npy',\n",
       " 'data/4.npy',\n",
       " 'data/5.npy',\n",
       " 'data/6.npy',\n",
       " 'data/7.npy',\n",
       " 'data/8.npy',\n",
       " 'data/9.npy']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(vocal_file_path, \"rt\") as f:\n",
    "    n_vocab = len(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(vocal_file_path, \"r\")\n",
    "vocab = [line.strip().split() for line in f.readlines()]\n",
    "vocab_list = [[line[0], int(line[1])] for line in vocab]\n",
    "vocab = {key: value for value, key  in vocab_list}\n",
    "vocab_array = np.array([word for word, _ in vocab_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/0.npy',\n",
       " 'data/1.npy',\n",
       " 'data/2.npy',\n",
       " 'data/3.npy',\n",
       " 'data/4.npy',\n",
       " 'data/5.npy',\n",
       " 'data/6.npy',\n",
       " 'data/7.npy',\n",
       " 'data/8.npy',\n",
       " 'data/9.npy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = len(data_list)\n",
    "class_weights = np.zeros(classes)\n",
    "result = []\n",
    "for cls in range(classes):\n",
    "    result.append(np.load(os.path.join(DATA_PATH,\"{}.npy\".format(cls))))\n",
    "    class_weights[cls] = len(result[cls])\n",
    "total_tokens = np.sum(class_weights)\n",
    "class_weights = total_tokens / class_weights\n",
    "class_weights = class_weights / np.mean(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'của'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sau cứu tự trở của máy phí tiger e cũng'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(vocab_array[result[0][:10].astype(int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228701"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7499, 256)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_arr = np.load(embedding_file_path)\n",
    "embedding_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12443245, -1.06767595, -0.86100352, -0.22868277, -0.18263325,\n",
       "       -0.83897579, -0.54271376, -0.14510156,  1.45080626, -1.31177831,\n",
       "       -0.09934112, -0.50401318,  0.18361984, -0.87430686,  0.4183397 ,\n",
       "       -0.38293737, -0.46698889, -0.3168374 ,  0.2094702 ,  0.0927381 ,\n",
       "       -0.40501601, -0.03243043, -0.97817194,  0.39318395,  0.44378737,\n",
       "       -0.09778501,  0.98345089,  0.38792226,  0.3072651 ,  0.69894433,\n",
       "       -0.61095971, -0.00980708,  0.17413437, -0.8591373 , -0.35638359,\n",
       "        0.50950557, -0.74880069, -0.86677134, -0.2526764 ,  0.42806679,\n",
       "        0.85238779, -0.4667412 , -0.82140058,  0.30189058,  0.24839553,\n",
       "        1.38992858,  0.50543082, -1.48028874, -0.01180037, -0.17234892,\n",
       "       -0.85603124,  0.20224749,  1.66323972, -0.66056222, -0.39488134,\n",
       "       -0.24969529,  0.45999593, -0.94671363, -0.10207363, -0.28477326,\n",
       "       -0.0461395 ,  0.36013049,  0.50129986,  0.64350557,  0.35307923,\n",
       "        0.62748319,  0.89732498,  0.78383476, -0.67000973, -0.22200827,\n",
       "        1.27343178,  0.13534789,  0.31721869, -0.57044595,  0.9380374 ,\n",
       "        0.1849466 , -0.05932492,  0.58230752,  0.2794989 ,  0.58284301,\n",
       "       -0.33176413,  0.08353724,  0.07803518,  0.54719353,  0.04042601,\n",
       "        0.79377317, -0.98359823, -0.17248534,  0.94746923,  1.08167624,\n",
       "        0.29200822, -0.93274468, -0.09038737,  1.09489608,  0.74701715,\n",
       "       -0.79815954,  1.18234742, -0.17418277,  0.74709642, -0.35062674,\n",
       "       -0.92918068, -0.6091522 , -1.61504459, -0.57081503,  0.51836842,\n",
       "       -0.27167344, -0.64415634, -0.34340453, -0.31937721,  0.40227783,\n",
       "        0.14110938, -0.18489535, -0.31190547, -0.09707518, -1.13831103,\n",
       "       -0.03060403,  0.05532103,  0.41910234,  0.5064913 ,  0.20697413,\n",
       "       -0.77982509, -0.38855946,  1.32394743, -0.01252114, -1.1908015 ,\n",
       "       -0.91041172, -0.3269321 ,  0.04807211,  0.04039547,  0.45401725,\n",
       "        0.46560881,  0.29006708, -0.93322331,  0.29449537,  0.15555881,\n",
       "       -1.29352438, -0.24779892,  1.13151443,  0.13305201,  0.30659148,\n",
       "        0.55671698, -0.63271862,  1.41367352,  0.55152506, -0.13650852,\n",
       "        0.3860403 ,  0.39579105, -0.48662415,  0.49589226, -0.24794549,\n",
       "        0.09146886, -0.16687322,  1.06093109, -1.13535202,  0.33511397,\n",
       "        0.1538215 , -1.10340822, -0.52809614, -0.05495086, -0.60985166,\n",
       "        0.66067338,  0.71280813, -0.02457188,  0.30794534,  1.80580652,\n",
       "       -0.89269644, -0.11685738,  1.56798625, -0.70332599, -0.41375443,\n",
       "        1.01321805,  0.01676766, -0.82164985,  0.10771663,  0.90039462,\n",
       "       -0.71154976,  0.1187866 , -0.25480273, -0.70745182,  0.14320678,\n",
       "       -0.59145045,  1.00864482, -1.47847581,  0.64857519, -0.21350351,\n",
       "        0.02757026,  0.60861248, -0.50019807, -0.66927934,  0.02646467,\n",
       "        0.08977167, -0.48468632, -1.14838469, -0.23971485,  0.49843907,\n",
       "        0.02221074,  0.57609344,  1.39113331,  0.20379485,  0.12621181,\n",
       "       -0.14323393, -0.48948401,  0.90595269, -0.08403202,  0.44562036,\n",
       "       -1.1656723 ,  1.16003478, -1.24297476, -0.64413476,  0.28897804,\n",
       "        0.23566014, -0.23261236,  0.62761408,  1.31588459, -0.02408398,\n",
       "       -1.5003581 , -0.21857543, -1.40996468,  1.01464701,  0.21464302,\n",
       "        0.54075444,  0.21971393, -1.266415  ,  0.30365172,  0.32249001,\n",
       "       -1.29328513, -0.76492673,  0.20409791,  0.70499682, -0.43712533,\n",
       "       -0.00415328, -0.55652356,  1.04865205, -0.22788893,  0.02263848,\n",
       "       -0.91300476, -0.25949126,  0.81881052,  0.97557068,  1.55272722,\n",
       "        0.3027795 , -0.23831415, -0.2968663 ,  0.36713853, -0.30203599,\n",
       "        0.46231312, -0.38108152,  0.61460167, -0.65460539,  0.56079513,\n",
       "       -0.51989937,  0.64149189,  0.18488634, -0.23134257, -0.86735821,\n",
       "       -0.750844  ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(10, 3)\n",
    "device = torch.device(\"cpu\")\n",
    "idx = torch.tensor([3, 5, 1, 2], dtype=torch.int64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(10, 3)\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0729, -0.9660, -2.2049],\n",
       "        [ 0.0266, -1.8962, -0.2807],\n",
       "        [-1.2198,  0.2665,  0.5991],\n",
       "        [-1.4453, -0.3937, -0.5637]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.tensor([3, 5, 1, 2], dtype=torch.int64, device=device)\n",
    "emb(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50,  325,  152,  198,    0,  199,  557, 1797, 2122,   19,  267,\n",
       "       1189, 1196,  789,  466, 1320,  207,   28, 2122,    3,  437,  335,\n",
       "        263,   50,  325,  152,  198,    0,   37,  267,   15,  902,  113,\n",
       "        789,  466,   64,  488,    4,   66,  158,  267,  105,  528, 1797,\n",
       "       2122,    1,  152,  198,    5,  410])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9026,  0.2722,  1.0176],\n",
       "        [-0.2384, -1.7833,  1.1430],\n",
       "        [ 0.2300, -1.0885,  0.8840],\n",
       "        [ 0.4738, -0.0573, -0.2484],\n",
       "        [-0.1403,  0.1988, -0.0471],\n",
       "        [-0.0246,  0.5285,  1.1919],\n",
       "        [ 0.3878,  0.3332, -1.8052],\n",
       "        [ 0.8330,  0.2166, -0.1915],\n",
       "        [-0.5946,  1.1952,  2.6624],\n",
       "        [ 1.7488, -0.4235,  2.9538]], requires_grad=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228701"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_embedding = Embeddings(len(vocab_list), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['là', 3]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['các', 5]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embeddings(\n",
       "  (lut): Embedding(512, 228701)\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.tensor([3, 5, 1, 2], dtype=torch.int64, device=device)\n",
    "\n",
    "my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  50,  325,  152,  198,    0,  199,  557, 1797, 2122,   19,  267, 1189,\n",
       "        1196,  789,  466, 1320,  207,   28, 2122,    3,  437,  335,  263,   50,\n",
       "         325,  152,  198,    0,   37,  267,   15,  902,  113,  789,  466,   64,\n",
       "         488,    4,   66,  158,  267,  105,  528, 1797, 2122,    1,  152,  198,\n",
       "           5,  410])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-65.7696,   4.6158,  -7.5767,  ...,  26.4757,  14.1369,  21.1667],\n",
       "        [ 31.3081,  -4.5238, -30.5610,  ..., -21.5612,   3.6226, -21.3581],\n",
       "        [  2.7889,   8.0909, -22.0422,  ...,  13.9054,  16.0605,  -1.5210],\n",
       "        ...,\n",
       "        [-44.6038,   5.2266, -31.4721,  ..., -20.8467,  37.2234, -13.7966],\n",
       "        [-21.8527,  34.9529,  -0.3339,  ..., -13.8139,  14.5244,  20.4514],\n",
       "        [ -9.8245, -54.6033,   3.9819,  ...,  33.5087,  37.8419,  36.8506]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embedding = Embeddings(512, len(vocab_list))\n",
    "idx = np.load(data_list[0])[:10].astype(int)\n",
    "idx = torch.tensor(idx, dtype=torch.int64, device=device)\n",
    "my_embedding(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  50,  325,  152,  198,    0,  199,  557, 1797, 2122,   19])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_embedding(idx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask,\n",
    "                                 dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        x = torch.squeeze(x)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)],\n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        # mean = torch.Tensor(x.mean(-1, keepdims=True)).to('cuda')\n",
    "        # std = torch.Tensor(x.std(-1, keepdims=True)).to('cuda')\n",
    "        # x = torch.Tensor(x).to('cuda')\n",
    "        mean = x.mean(-1,keepdim=True)\n",
    "        std = x.std(-1,keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity we apply the norm first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer function that maintains the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of two sublayers, self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base model for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, src_embed, batch_size, d_model, n_class):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed\n",
    "        self.linear = nn.Linear(d_model, n_class)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        enc = self.encoder(src, src_mask)\n",
    "        # flat = enc.reshape(-1).unsqueeze(0)\n",
    "        lin = self.linear(enc)\n",
    "        result = F.softmax(lin, dim=1)\n",
    "        return result\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=6\n",
    "d_model=128\n",
    "d_ff=2048\n",
    "h=8\n",
    "dropout=0.1\n",
    "batch_size=10\n",
    "n_class=10\n",
    "src_vocab = len(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = copy.deepcopy\n",
    "attn = MultiHeadedAttention(h, d_model)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "position = PositionalEncoding(d_model, dropout)\n",
    "model = TransformerEncoder(\n",
    "    Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "    nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "    batch_size,\n",
    "    d_model,\n",
    "    n_class\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'gpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _select_examples(X, maxlen):\n",
    "    begin = np.random.randint(len(X) - maxlen)\n",
    "    return X[begin: begin + maxlen]\n",
    "\n",
    "\n",
    "def next_batch(X, batch_size, maxlen):\n",
    "    x = np.zeros(shape=[batch_size, maxlen + 1])\n",
    "    choices = np.random.randint(len(X), size=batch_size)\n",
    "    for idx, choice in enumerate(choices):\n",
    "        x[idx, :-1] = _select_examples(X[choice], maxlen)\n",
    "        x[idx, -1] = choice\n",
    "    Y = np.expand_dims(x[:, -1], 1).copy()\n",
    "    x = x[:, :-1].copy()\n",
    "    return x, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next_batch(result, batch_size, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  11, 1338,   66, 1069, 2009,  111,  147,    1,   44,   76,   13,\n",
       "         75,  212,   28,  765,  200, 1061,  451,   20,    1,  316,    5,\n",
       "         24,  303, 1658,   11, 1338,    2,   44,   25,   42,  309,  862,\n",
       "        291, 1948,  227,   11,   76,    1,  474,  239, 3128,    1, 3128,\n",
       "         12,   34,   36,  824,  640, 6707,    0,  317,  663, 1534,    5,\n",
       "        575,    6,  765,  200,    3,    8,  231,  547,    1,   14,    0,\n",
       "        395,  160,  150, 6851, 5658,  640, 6707,    4,  239,  129,  824,\n",
       "          3,  316,   30,    7,  191,   95, 1136,    1,   96,  794,  640,\n",
       "         20,    6,  570,  522,  207,  308,  291,    4,    3,  795,  104,\n",
       "         13,  269,   11,  547,    0,  230,  249,    1,   14,    0,   25,\n",
       "         13,   98,   49,   27,  137,   18, 3071,  824,  640,   50, 1271,\n",
       "       4623,    4,   11,  295,   63,  231,   96])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x, dtype=torch.float, device=device)\n",
    "y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "y = torch.squeeze(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(model, lr=0.005):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr)\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, optimizer = get_criterion(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: loss= 2.244738817214966, accuracy= 0.19423828125\n",
      "Iteration 100: loss= 2.238743543624878, accuracy= 0.2013671875\n",
      "Iteration 200: loss= 2.2390854358673096, accuracy= 0.20419921875\n",
      "Iteration 300: loss= 2.2391865253448486, accuracy= 0.19443359375\n",
      "Iteration 400: loss= 2.2368602752685547, accuracy= 0.204296875\n",
      "Iteration 500: loss= 2.2372307777404785, accuracy= 0.20146484375\n",
      "Iteration 600: loss= 2.2422876358032227, accuracy= 0.19716796875\n",
      "Iteration 700: loss= 2.234327793121338, accuracy= 0.2052734375\n",
      "Iteration 800: loss= 2.238388776779175, accuracy= 0.198828125\n",
      "Iteration 900: loss= 2.243783712387085, accuracy= 0.19765625\n",
      "Iteration 1000: loss= 2.236576557159424, accuracy= 0.20400390625\n",
      "Iteration 1100: loss= 2.238525867462158, accuracy= 0.20322265625\n",
      "Iteration 1200: loss= 2.2429122924804688, accuracy= 0.197265625\n",
      "Iteration 1300: loss= 2.234954833984375, accuracy= 0.2056640625\n",
      "Iteration 1400: loss= 2.2398884296417236, accuracy= 0.196875\n",
      "Iteration 1500: loss= 2.2472012042999268, accuracy= 0.19091796875\n",
      "Iteration 1600: loss= 2.2410085201263428, accuracy= 0.20087890625\n",
      "Iteration 1700: loss= 2.2480311393737793, accuracy= 0.1890625\n",
      "Iteration 1800: loss= 2.2358365058898926, accuracy= 0.20048828125\n",
      "Iteration 1900: loss= 2.2416188716888428, accuracy= 0.1939453125\n",
      "Iteration 2000: loss= 2.245300769805908, accuracy= 0.191796875\n",
      "Iteration 2100: loss= 2.2434964179992676, accuracy= 0.19482421875\n",
      "Iteration 2200: loss= 2.242549419403076, accuracy= 0.19423828125\n",
      "Iteration 2300: loss= 2.2432587146759033, accuracy= 0.19150390625\n",
      "Iteration 2400: loss= 2.243417501449585, accuracy= 0.19677734375\n",
      "Iteration 2500: loss= 2.243957757949829, accuracy= 0.19443359375\n",
      "Iteration 2600: loss= 2.241084098815918, accuracy= 0.19833984375\n",
      "Iteration 2700: loss= 2.2429583072662354, accuracy= 0.1962890625\n",
      "Iteration 2800: loss= 2.2371714115142822, accuracy= 0.20263671875\n",
      "Iteration 2900: loss= 2.2425522804260254, accuracy= 0.198046875\n",
      "Iteration 3000: loss= 2.2457664012908936, accuracy= 0.19130859375\n",
      "Iteration 3100: loss= 2.2384033203125, accuracy= 0.19921875\n",
      "Iteration 3200: loss= 2.2411627769470215, accuracy= 0.19931640625\n",
      "Iteration 3300: loss= 2.2451443672180176, accuracy= 0.19267578125\n",
      "Iteration 3400: loss= 2.2495458126068115, accuracy= 0.1873046875\n",
      "Iteration 3500: loss= 2.2513179779052734, accuracy= 0.188671875\n",
      "Iteration 3600: loss= 2.2460246086120605, accuracy= 0.18974609375\n",
      "Iteration 3700: loss= 2.241915702819824, accuracy= 0.19501953125\n",
      "Iteration 3800: loss= 2.2477262020111084, accuracy= 0.18994140625\n",
      "Iteration 3900: loss= 2.243886709213257, accuracy= 0.19482421875\n",
      "Iteration 4000: loss= 2.247148275375366, accuracy= 0.191796875\n",
      "Iteration 4100: loss= 2.2471752166748047, accuracy= 0.18564453125\n",
      "Iteration 4200: loss= 2.2469847202301025, accuracy= 0.19677734375\n",
      "Iteration 4300: loss= 2.2410521507263184, accuracy= 0.19609375\n",
      "Iteration 4400: loss= 2.2505745887756348, accuracy= 0.184375\n",
      "Iteration 4500: loss= 2.2470695972442627, accuracy= 0.19013671875\n",
      "Iteration 4600: loss= 2.24881911277771, accuracy= 0.18740234375\n",
      "Iteration 4700: loss= 2.2492403984069824, accuracy= 0.187890625\n",
      "Iteration 4800: loss= 2.2468175888061523, accuracy= 0.1916015625\n",
      "Iteration 4900: loss= 2.2522480487823486, accuracy= 0.18388671875\n",
      "Iteration 5000: loss= 2.2467827796936035, accuracy= 0.1916015625\n",
      "Iteration 5100: loss= 2.247798442840576, accuracy= 0.18896484375\n",
      "Iteration 5200: loss= 2.245995283126831, accuracy= 0.192578125\n",
      "Iteration 5300: loss= 2.2513985633850098, accuracy= 0.1845703125\n",
      "Iteration 5400: loss= 2.2477219104766846, accuracy= 0.19052734375\n",
      "Iteration 5500: loss= 2.248267412185669, accuracy= 0.19228515625\n",
      "Iteration 5600: loss= 2.250566244125366, accuracy= 0.18525390625\n",
      "Iteration 5700: loss= 2.249598264694214, accuracy= 0.1859375\n",
      "Iteration 5800: loss= 2.2391865253448486, accuracy= 0.2009765625\n",
      "Iteration 5900: loss= 2.248903274536133, accuracy= 0.188671875\n",
      "Iteration 6000: loss= 2.243715763092041, accuracy= 0.1943359375\n",
      "Iteration 6100: loss= 2.245675802230835, accuracy= 0.1943359375\n",
      "Iteration 6200: loss= 2.2500338554382324, accuracy= 0.1876953125\n",
      "Iteration 6300: loss= 2.247396945953369, accuracy= 0.19384765625\n",
      "Iteration 6400: loss= 2.245532512664795, accuracy= 0.1916015625\n",
      "Iteration 6500: loss= 2.2497284412384033, accuracy= 0.1912109375\n",
      "Iteration 6600: loss= 2.247138500213623, accuracy= 0.1939453125\n",
      "Iteration 6700: loss= 2.256080150604248, accuracy= 0.1814453125\n",
      "Iteration 6800: loss= 2.2516462802886963, accuracy= 0.186328125\n",
      "Iteration 6900: loss= 2.2550737857818604, accuracy= 0.18095703125\n",
      "Iteration 7000: loss= 2.2500925064086914, accuracy= 0.18681640625\n",
      "Iteration 7100: loss= 2.243527889251709, accuracy= 0.19248046875\n",
      "Iteration 7200: loss= 2.2508838176727295, accuracy= 0.18779296875\n",
      "Iteration 7300: loss= 2.2520828247070312, accuracy= 0.18671875\n",
      "Iteration 7400: loss= 2.24473237991333, accuracy= 0.19150390625\n",
      "Iteration 7500: loss= 2.2478291988372803, accuracy= 0.19111328125\n",
      "Iteration 7600: loss= 2.24806809425354, accuracy= 0.1892578125\n",
      "Iteration 7700: loss= 2.2440459728240967, accuracy= 0.19306640625\n",
      "Iteration 7800: loss= 2.2484469413757324, accuracy= 0.1865234375\n",
      "Iteration 7900: loss= 2.250587224960327, accuracy= 0.19072265625\n",
      "Iteration 8000: loss= 2.243657350540161, accuracy= 0.19501953125\n",
      "Iteration 8100: loss= 2.2478690147399902, accuracy= 0.1953125\n",
      "Iteration 8200: loss= 2.2524046897888184, accuracy= 0.18798828125\n",
      "Iteration 8300: loss= 2.2515041828155518, accuracy= 0.18681640625\n",
      "Iteration 8400: loss= 2.2442173957824707, accuracy= 0.19248046875\n",
      "Iteration 8500: loss= 2.2489378452301025, accuracy= 0.19208984375\n",
      "Iteration 8600: loss= 2.2460570335388184, accuracy= 0.18818359375\n",
      "Iteration 8700: loss= 2.247124195098877, accuracy= 0.19248046875\n",
      "Iteration 8800: loss= 2.245392322540283, accuracy= 0.1876953125\n",
      "Iteration 8900: loss= 2.247929334640503, accuracy= 0.1888671875\n",
      "Iteration 9000: loss= 2.247635841369629, accuracy= 0.19072265625\n",
      "Iteration 9100: loss= 2.242492914199829, accuracy= 0.19443359375\n",
      "Iteration 9200: loss= 2.2475311756134033, accuracy= 0.191796875\n",
      "Iteration 9300: loss= 2.2475411891937256, accuracy= 0.1923828125\n",
      "Iteration 9400: loss= 2.246720314025879, accuracy= 0.1888671875\n",
      "Iteration 9500: loss= 2.242506265640259, accuracy= 0.1984375\n",
      "Iteration 9600: loss= 2.2463176250457764, accuracy= 0.19462890625\n",
      "Iteration 9700: loss= 2.241764545440674, accuracy= 0.1998046875\n",
      "Iteration 9800: loss= 2.240837574005127, accuracy= 0.1994140625\n",
      "Iteration 9900: loss= 2.251131534576416, accuracy= 0.186328125\n",
      "Iteration 10000: loss= 2.251405954360962, accuracy= 0.190234375\n",
      "Iteration 10100: loss= 2.2532525062561035, accuracy= 0.18515625\n",
      "Iteration 10200: loss= 2.2367513179779053, accuracy= 0.20146484375\n",
      "Iteration 10300: loss= 2.248237133026123, accuracy= 0.18994140625\n",
      "Iteration 10400: loss= 2.248196840286255, accuracy= 0.18759765625\n",
      "Iteration 10500: loss= 2.2428252696990967, accuracy= 0.1984375\n",
      "Iteration 10600: loss= 2.244499683380127, accuracy= 0.193359375\n",
      "Iteration 10700: loss= 2.248464822769165, accuracy= 0.1865234375\n",
      "Iteration 10800: loss= 2.2441184520721436, accuracy= 0.19287109375\n",
      "Iteration 10900: loss= 2.2476351261138916, accuracy= 0.187890625\n",
      "Iteration 11000: loss= 2.2399837970733643, accuracy= 0.19912109375\n",
      "Iteration 11100: loss= 2.2502846717834473, accuracy= 0.18603515625\n",
      "Iteration 11200: loss= 2.2465012073516846, accuracy= 0.190625\n",
      "Iteration 11300: loss= 2.2466518878936768, accuracy= 0.19189453125\n",
      "Iteration 11400: loss= 2.242889404296875, accuracy= 0.1970703125\n",
      "Iteration 11500: loss= 2.2436957359313965, accuracy= 0.19609375\n",
      "Iteration 11600: loss= 2.2404637336730957, accuracy= 0.20029296875\n",
      "Iteration 11700: loss= 2.2458248138427734, accuracy= 0.1935546875\n",
      "Iteration 11800: loss= 2.2499687671661377, accuracy= 0.1849609375\n",
      "Iteration 11900: loss= 2.2460031509399414, accuracy= 0.192578125\n",
      "Iteration 12000: loss= 2.2422239780426025, accuracy= 0.20234375\n",
      "Iteration 12100: loss= 2.243032932281494, accuracy= 0.19541015625\n",
      "Iteration 12200: loss= 2.2474205493927, accuracy= 0.1916015625\n",
      "Iteration 12300: loss= 2.2494492530822754, accuracy= 0.187890625\n",
      "Iteration 12400: loss= 2.240020275115967, accuracy= 0.1986328125\n",
      "Iteration 12500: loss= 2.2439723014831543, accuracy= 0.19521484375\n",
      "Iteration 12600: loss= 2.243833303451538, accuracy= 0.197265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12700: loss= 2.239049196243286, accuracy= 0.1986328125\n",
      "Iteration 12800: loss= 2.249934673309326, accuracy= 0.1853515625\n",
      "Iteration 12900: loss= 2.2445991039276123, accuracy= 0.1962890625\n",
      "Iteration 13000: loss= 2.242706298828125, accuracy= 0.19443359375\n",
      "Iteration 13100: loss= 2.2399590015411377, accuracy= 0.199609375\n",
      "Iteration 13200: loss= 2.2438242435455322, accuracy= 0.1951171875\n",
      "Iteration 13300: loss= 2.245129108428955, accuracy= 0.192578125\n",
      "Iteration 13400: loss= 2.2398483753204346, accuracy= 0.19697265625\n",
      "Iteration 13500: loss= 2.246515989303589, accuracy= 0.19130859375\n",
      "Iteration 13600: loss= 2.24682354927063, accuracy= 0.1900390625\n",
      "Iteration 13700: loss= 2.2456953525543213, accuracy= 0.1884765625\n",
      "Iteration 13800: loss= 2.244171619415283, accuracy= 0.19208984375\n",
      "Iteration 13900: loss= 2.243431568145752, accuracy= 0.19306640625\n",
      "Iteration 14000: loss= 2.2432923316955566, accuracy= 0.195703125\n",
      "Iteration 14100: loss= 2.235433578491211, accuracy= 0.20615234375\n",
      "Iteration 14200: loss= 2.2459521293640137, accuracy= 0.1923828125\n",
      "Iteration 14300: loss= 2.242680788040161, accuracy= 0.19609375\n",
      "Iteration 14400: loss= 2.2423949241638184, accuracy= 0.1951171875\n",
      "Iteration 14500: loss= 2.2417471408843994, accuracy= 0.19453125\n",
      "Iteration 14600: loss= 2.239802360534668, accuracy= 0.1994140625\n",
      "Iteration 14700: loss= 2.242243528366089, accuracy= 0.1958984375\n",
      "Iteration 14800: loss= 2.2435812950134277, accuracy= 0.19580078125\n",
      "Iteration 14900: loss= 2.240870714187622, accuracy= 0.1986328125\n",
      "Iteration 15000: loss= 2.2414040565490723, accuracy= 0.19873046875\n",
      "Iteration 15100: loss= 2.246774196624756, accuracy= 0.1927734375\n",
      "Iteration 15200: loss= 2.2418322563171387, accuracy= 0.1998046875\n",
      "Iteration 15300: loss= 2.2411742210388184, accuracy= 0.19921875\n",
      "Iteration 15400: loss= 2.243253231048584, accuracy= 0.19599609375\n",
      "Iteration 15500: loss= 2.238408327102661, accuracy= 0.2025390625\n",
      "Iteration 15600: loss= 2.246626138687134, accuracy= 0.19267578125\n",
      "Iteration 15700: loss= 2.240934371948242, accuracy= 0.199609375\n",
      "Iteration 15800: loss= 2.242158889770508, accuracy= 0.19638671875\n",
      "Iteration 15900: loss= 2.242586851119995, accuracy= 0.19521484375\n",
      "Iteration 16000: loss= 2.2425360679626465, accuracy= 0.1962890625\n",
      "Iteration 16100: loss= 2.2441253662109375, accuracy= 0.1916015625\n",
      "Iteration 16200: loss= 2.2477054595947266, accuracy= 0.18896484375\n",
      "Iteration 16300: loss= 2.2390809059143066, accuracy= 0.20244140625\n",
      "Iteration 16400: loss= 2.2467427253723145, accuracy= 0.19130859375\n",
      "Iteration 16500: loss= 2.2410902976989746, accuracy= 0.19560546875\n",
      "Iteration 16600: loss= 2.2437024116516113, accuracy= 0.1931640625\n",
      "Iteration 16700: loss= 2.24311900138855, accuracy= 0.1943359375\n",
      "Iteration 16800: loss= 2.24426007270813, accuracy= 0.191015625\n",
      "Iteration 16900: loss= 2.242283582687378, accuracy= 0.19619140625\n",
      "Iteration 17000: loss= 2.239008903503418, accuracy= 0.2009765625\n",
      "Iteration 17100: loss= 2.2442479133605957, accuracy= 0.19619140625\n",
      "Iteration 17200: loss= 2.240671157836914, accuracy= 0.198046875\n",
      "Iteration 17300: loss= 2.240858316421509, accuracy= 0.19794921875\n",
      "Iteration 17400: loss= 2.241016149520874, accuracy= 0.19951171875\n",
      "Iteration 17500: loss= 2.239023208618164, accuracy= 0.1990234375\n",
      "Iteration 17600: loss= 2.2406156063079834, accuracy= 0.1990234375\n",
      "Iteration 17700: loss= 2.238924026489258, accuracy= 0.2001953125\n",
      "Iteration 17800: loss= 2.241499423980713, accuracy= 0.2\n",
      "Iteration 17900: loss= 2.24491810798645, accuracy= 0.188671875\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 100000\n",
    "dim_model = 128\n",
    "batch_size= 10240\n",
    "\n",
    "X = result\n",
    "for iter in range(num_iterations):\n",
    "    x, y = next_batch(X, batch_size, dim_model)\n",
    "    x = torch.tensor(x, dtype=torch.float, device=device)\n",
    "    y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "    y = torch.squeeze(y)\n",
    "    criterion, optimizer = get_criterion(model)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x, None)\n",
    "    loss = criterion(output,y)\n",
    "    if iter % 100 == 0:\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "        print(\"Iteration {}: loss= {}, accuracy= {}\".format(\n",
    "            iter,loss.item(), float(torch.sum(preds==y).item()/batch_size)))\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lablup FF 20.07 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
